{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3500c382-3a00-4117-b119-805834917f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo\n",
      "sw5.pdf\n",
      "count\n",
      "15\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [10/Oct/2023 11:55:59] \"OPTIONS /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Request 'http://localhost:5000/chat' [POST]>\n",
      "what is shareworks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Oct/2023 11:56:21] \"POST /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result  Shareworks is a suite of financial solutions offered by Morgan Stanley at Work. It is a platform that provides equity compensation services, allowing employees to manage their stock plans and equity awards. Shareworks helps employees track and manage their stock options, restricted stock units, and other equity-based compensation. It is provided by Morgan Stanley Smith Barney LLC, a subsidiary of Morgan Stanley.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Oct/2023 11:57:06] \"OPTIONS /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Request 'http://localhost:5000/chat' [POST]>\n",
      "How to connect bank account with stock plan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Oct/2023 11:57:36] \"POST /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result  To link your bank account with your stock plan account, follow these steps:\n",
      "\n",
      "1. Login to your stock plan account.\n",
      "2. Click on \"View profile.\"\n",
      "3. Select \"Manage deposits.\"\n",
      "4. Activate the \"Add Account\" control.\n",
      "5. Click on \"Link account instantly.\"\n",
      "6. Agree to the disclosure.\n",
      "7. The \"Confirm\" button will activate. Click it to start the process.\n",
      "8. A search bar will appear, allowing you to search for your desired institution.\n",
      "9. Authenticate with your online banking credentials.\n",
      "10. Select your bank account from the list of accounts.\n",
      "11. Save and finish the process.\n",
      "\n",
      "Please note that these steps may vary depending on the specific platform or service you are using for your stock plan account.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Oct/2023 11:57:48] \"OPTIONS /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Request 'http://localhost:5000/chat' [POST]>\n",
      "what is 10b5 plan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Oct/2023 11:58:11] \"POST /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result  A 10b5-1 plan, also known as a Rule 10b5-1 plan, is a trading plan that allows insiders of a company to buy or sell their company's stock in a predetermined manner, even if they possess material nonpublic information (MNPI). These plans are established in advance and are intended to provide insiders with a defense against allegations of insider trading. The plan outlines specific instructions for buying or selling shares at predetermined times or prices, regardless of any subsequent MNPI that the insider may come into possession of.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "127.0.0.1 - - [10/Oct/2023 12:03:31] \"POST /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result  This document discusses comments received by the Commission regarding proposed amendments to certain reporting forms. The comments argue for a more bright-line approach to reporting events, rather than using a materiality standard. The commenters believe that this approach would benefit investors by providing consistent and material information while reducing the burden on issuers. One commenter also suggests removing or changing the trigger for share repurchase disclosure. Another commenter believes that the proposed narrative disclosure adequately addresses concerns about timing of stock option awards. The document also mentions amendments to Forms 4 and 5, including the addition of a Rule 10b5-1 checkbox and the reporting of gifts of equity securities. The document anticipates that the direct costs of preparing disclosures will be relatively small and discusses the potential impact on small filers and competition.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA,  ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "import datetime\n",
    "sys.path.append('../..')\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "\n",
    "current_date = datetime.datetime.now().date()\n",
    "if current_date < datetime.date(2023, 9, 2):\n",
    "    llm_name = \"gpt-3.5-turbo-0301\"\n",
    "else:\n",
    "    llm_name = \"gpt-3.5-turbo\"\n",
    "print(llm_name)\n",
    "\n",
    "persist_directory = 'docs/chroma/'\n",
    "\n",
    "def load_db(file, chain_type, k):\n",
    "    print(file)\n",
    "    loaders = [\n",
    "        # Duplicate documents on purpose - messy data\n",
    "#         PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture02.pdf\"),\n",
    "        PyPDFLoader(file)\n",
    "    ]\n",
    "    docList = []\n",
    "    for loader in loaders:\n",
    "        print('count')\n",
    "        docList.extend(loader.load())\n",
    "\n",
    "    print(len(docList))\n",
    "        \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 1500,\n",
    "        chunk_overlap = 150\n",
    "    )    \n",
    "    docs = text_splitter.split_documents(docList)\n",
    "    \n",
    "    # define embedding\n",
    "    embedding = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
    "    \n",
    "     # create vector database from data\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embedding,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    retriever=vectordb.as_retriever()\n",
    "    \n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        return_messages=True\n",
    "    )\n",
    "    # define retriever\n",
    "    # create a chatbot chain. Memory is managed externally.\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=llm_name, temperature=0, openai_api_key=openai.api_key), \n",
    "        chain_type=chain_type, \n",
    "        retriever=retriever, \n",
    "        memory=memory\n",
    "    )\n",
    "    return qa \n",
    "\n",
    "import param\n",
    "\n",
    "class cbfs(param.Parameterized):\n",
    "#     chat_history = param.List([])\n",
    "    answer = param.String(\"\")\n",
    "    db_query  = param.String(\"\")\n",
    "    db_response = param.List([])\n",
    "    \n",
    "    def __init__(self,  **params):\n",
    "        super(cbfs, self).__init__( **params)\n",
    "        self.loaded_file = \"sw5.pdf\"\n",
    "        self.qa = load_db(self.loaded_file,\"stuff\", 4)\n",
    "    \n",
    "\n",
    "    def convchain(self, query):\n",
    "        result = self.qa({\"question\": query})\n",
    "        self.answer = result['answer'] \n",
    "        return self.answer\n",
    "    \n",
    "    def clr_history(self,count=0):\n",
    "        self.chat_history = []\n",
    "        return \n",
    "\n",
    "cb = cbfs()\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "def process_input(input_string):\n",
    "    return cb.convchain(input_string)\n",
    "\n",
    "@app.route('/chat', methods=['POST'])\n",
    "def post_example():\n",
    "    try:\n",
    "        print(request)\n",
    "        # Get the string from the request body\n",
    "        data = request.json\n",
    "        print(data['message'])\n",
    "        result = process_input(data['message'])\n",
    "        print('result ' , result)\n",
    "        return jsonify({\"reply\": result})\n",
    "        # return result    \n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "# @app.route('/api', methods=['GET'])\n",
    "# def get_string():\n",
    "#     try:\n",
    "#         # Get the input string from the query parameters\n",
    "#         input_string = request.args.get('query')\n",
    "\n",
    "#         # Process the input string (you can add your logic here)\n",
    "#         output_string = process_input(input_string)\n",
    "\n",
    "#         # Return the output as JSON\n",
    "#         response = {'output_string': output_string}\n",
    "#         return jsonify(response)\n",
    "#     except Exception as e:\n",
    "#         return jsonify({'error': str(e)}), 400\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada0cf0-511d-43f5-af91-db222437293e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
