{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3500c382-3a00-4117-b119-805834917f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo\n",
      "sw.pdf\n",
      "count\n",
      "33\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [22/Sep/2023 10:04:25] \"GET /api?query='what%20is%20SW' HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Sep/2023 10:04:54] \"GET /api?query=shareworks HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Sep/2023 10:04:59] \"GET /api?query=shareworks HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA,  ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "import datetime\n",
    "sys.path.append('../..')\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "\n",
    "current_date = datetime.datetime.now().date()\n",
    "if current_date < datetime.date(2023, 9, 2):\n",
    "    llm_name = \"gpt-3.5-turbo-0301\"\n",
    "else:\n",
    "    llm_name = \"gpt-3.5-turbo\"\n",
    "print(llm_name)\n",
    "\n",
    "persist_directory = 'docs/chroma/'\n",
    "\n",
    "def load_db(file, chain_type, k):\n",
    "    print(file)\n",
    "    loaders = [\n",
    "        # Duplicate documents on purpose - messy data\n",
    "#         PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture02.pdf\"),\n",
    "        PyPDFLoader(file)\n",
    "    ]\n",
    "    docList = []\n",
    "    for loader in loaders:\n",
    "        print('count')\n",
    "        docList.extend(loader.load())\n",
    "\n",
    "    print(len(docList))\n",
    "        \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 1500,\n",
    "        chunk_overlap = 150\n",
    "    )    \n",
    "    docs = text_splitter.split_documents(docList)\n",
    "    \n",
    "    # define embedding\n",
    "    embedding = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
    "    \n",
    "     # create vector database from data\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embedding,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    retriever=vectordb.as_retriever()\n",
    "    \n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        return_messages=True\n",
    "    )\n",
    "    # define retriever\n",
    "    # create a chatbot chain. Memory is managed externally.\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=llm_name, temperature=0, openai_api_key=openai.api_key), \n",
    "        chain_type=chain_type, \n",
    "        retriever=retriever, \n",
    "        memory=memory\n",
    "    )\n",
    "    return qa \n",
    "\n",
    "import param\n",
    "\n",
    "class cbfs(param.Parameterized):\n",
    "#     chat_history = param.List([])\n",
    "    answer = param.String(\"\")\n",
    "    db_query  = param.String(\"\")\n",
    "    db_response = param.List([])\n",
    "    \n",
    "    def __init__(self,  **params):\n",
    "        super(cbfs, self).__init__( **params)\n",
    "        self.loaded_file = \"sw.pdf\"\n",
    "        self.qa = load_db(self.loaded_file,\"stuff\", 4)\n",
    "    \n",
    "\n",
    "    def convchain(self, query):\n",
    "        result = self.qa({\"question\": query})\n",
    "        self.answer = result['answer'] \n",
    "        return self.answer\n",
    "    \n",
    "    def clr_history(self,count=0):\n",
    "        self.chat_history = []\n",
    "        return \n",
    "\n",
    "cb = cbfs()\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/api', methods=['GET'])\n",
    "def get_string():\n",
    "    try:\n",
    "        # Get the input string from the query parameters\n",
    "        input_string = request.args.get('query')\n",
    "\n",
    "        # Process the input string (you can add your logic here)\n",
    "        output_string = process_input(input_string)\n",
    "\n",
    "        # Return the output as JSON\n",
    "        response = {'output_string': output_string}\n",
    "        return jsonify(response)\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 400\n",
    "\n",
    "def process_input(input_string):\n",
    "    return cb.convchain(input_string)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada0cf0-511d-43f5-af91-db222437293e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

